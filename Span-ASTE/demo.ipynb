{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "izKXA4b6-oIv",
    "outputId": "ede22721-eb64-48e0-a2ef-26f02674577c"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/chiayewken/Span-ASTE.git\n",
    "# !cd Span-ASTE && git checkout 7cbf035\n",
    "# !cd Span-ASTE && git checkout 92bc9a0\n",
    "!cd Span-ASTE && git checkout 16c7937\n",
    "!cp -a Span-ASTE/* .\n",
    "!echo boto3==1.16.46 >> requirements.txt\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "-pTnCgDxcSQ5",
    "outputId": "5907f7cb-531d-41a4-a75c-054e5243a5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['It', 'is', 'sporty', ',', 'but', 'not', 'fast', '.', 'If', 'you', 'understand', 'what', 'I', 'mean', 'by', 'that', 'character', 'of', 'the', 'car', 'is', 'more', 'of', 'a', 'relaxed', 'grand', 'tour', '.', 'Even', 'when', 'you', 'do', 'change', 'the', 'shift', 'points', 'and', 'the', 'suspension', 'setting', 'in', 'the', 'wheel', 'dynamics', ',', 'it', 'just', 'feels', 'like', 'it', 'wants', 'to', 'go', 'straight', ',', 'as', 'opposed', 'to', 'making', 'a', 'lot', 'of', 'turns', 'out', '.', \"That's\", 'not', 'a', 'bad', 'thing', '.', 'Every', 'car', 'can', 'be', 'a', 'canyon', 'carver', '.']\n",
      "target: (19, 19)\n",
      "opinion: (2, 2)\n",
      "label: LabelEnum.positive\n",
      "target: (19, 19)\n",
      "opinion: (5, 6)\n",
      "label: LabelEnum.positive\n",
      "\n",
      "tokens: ['But', 'you', 'know', 'what', '?', 'You', \"can't\", 'hear', 'Torque', '.', 'You', 'can', 'feel', 'it', '.', 'So', \"let's\", 'take', 'it', 'to', '60', 'and', 'you', 'can', 'really', 'feel', 'the', 'power', '.', 'You', \"won't\", 'hear', 'it', '.', '128', 'feet', 'of', 'torque', 'thing', 'is', 'a', 'little', 'vehicle', '.', \"It's\", 'really', 'not', 'that', 'big', '.', 'No', ',', \"it's\", 'not', '.', 'And', \"it's\", 'got', 'so', 'much', 'torque', 'that', 'it', 'will', 'pull', 'your', 'face', 'off', '.']\n",
      "target: (8, 8)\n",
      "opinion: (11, 13)\n",
      "label: LabelEnum.positive\n",
      "target: (27, 27)\n",
      "opinion: (11, 12)\n",
      "label: LabelEnum.positive\n",
      "target: (27, 27)\n",
      "opinion: (30, 7)\n",
      "label: LabelEnum.positive\n",
      "target: (8, 8)\n",
      "opinion: (15, 59)\n",
      "label: LabelEnum.positive\n",
      "target: (8, 8)\n",
      "opinion: (64, 67)\n",
      "label: LabelEnum.positive\n",
      "\n",
      "tokens: ['Adding', 'the', 'M', 'performance', 'version', 'was', 'an', 'a', 'plus', 'move', 'in', 'our', 'book', ',', 'considering', 'the', 'X3', 'competition', 'reads', 'like', 'a', \"who's\", 'who', 'of', 'first', 'world', 'problems', ',', 'some', 'of', 'whom', 'offer', 'legitimate', 'high', 'performance', 'track', 'where', 'the', 'options', 'portion', 'Makhan', 'with', 'the', 'performance', 'package', '.', 'Audi', 'S', 'Q5', ',', 'the', 'Mercedes-Benz', 'AM', 'GLC', '43', '63', 'the', 'Alfa', 'Romeo', 'Stelvio', 'Quadra', 'Folio', '.', 'Also', 'vying', 'for', 'your', 'luxury', 'SUV', 'allowance', '.', 'R', 'Jag', 'U', 'Ars', 'F', 'aced', 'Lexus', 'and', 'X', 'Range', 'Rovers', ',', 'Volare', ',', 'Accurate', 'RDX', 'and', 'the', 'Volvo', 'XC60', '.', \"It's\", 'a', 'pool', 'party', 'and', 'everyone', 'is', 'invited', '.']\n",
      "target: (2, 4)\n",
      "opinion: (8, 9)\n",
      "label: LabelEnum.positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Data Exploration\n",
    "data_name = \"muse\" #@param [\"14lap\", \"14res\", \"15res\", \"16res\"]\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from data_utils import Data\n",
    "\n",
    "path = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
    "data = Data.load_from_full_path(path)\n",
    "\n",
    "for s in data.sentences[:3]:\n",
    "    print(\"tokens:\", s.tokens)\n",
    "    for t in s.triples:\n",
    "        print(\"target:\", (t.t_start, t.t_end))\n",
    "        print(\"opinion:\", (t.o_start, t.o_end))\n",
    "        print(\"label:\", t.label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "3LmrJekiPHpQ",
    "outputId": "5cbed6cd-bf36-4532-8cc3-6fd27ea2a82e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-18 17:04:23--  https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/muse.tar\n",
      "Resolving github.com (github.com)... 4.208.26.197\n",
      "Connecting to github.com (github.com)|4.208.26.197|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2024-07-18 17:04:23 ERROR 404: Not Found.\n",
      "\n",
      "tar: muse.tar: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "# Download pretrained SpanModel weights\n",
    "from pathlib import Path\n",
    "template = \"https://github.com/chiayewken/Span-ASTE/releases/download/v1.0.0/{}.tar\"\n",
    "url = template.format(data_name)\n",
    "model_tar = Path(url).name\n",
    "model_dir = Path(url).stem\n",
    "\n",
    "!wget -nc $url\n",
    "!tar -xf $model_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPUtil in /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already satisfied: numba in /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages (0.56.4)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages (from numba) (0.39.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages (from numba) (1.21.5)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages (from numba) (65.6.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages (from numba) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages (from importlib-metadata->numba) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages (from importlib-metadata->numba) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil\n",
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=garbage_collection_threshold:0.6,max_split_size_mb:128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 73% | 61% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% | 96% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 90% | 61% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% | 96% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "import gc\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='2, 3'\n",
    "\n",
    "def free_gpu_cache():\n",
    "    #print(torch.cuda.memory_summary())\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()\n",
    "    #print(torch.cuda.list_gpu_processes())\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "   #print(torch.cuda.memory_summary())\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()\n",
    "    #cuda.select_device(0)\n",
    "\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 24.04 LTS\n",
      "Release:\t24.04\n",
      "Codename:\tnoble\n",
      "Cython version 0.29.21\n",
      "Name: jsonnet\n",
      "Version: 0.20.0\n",
      "Summary: Python bindings for Jsonnet - The data templating language \n",
      "Home-page: https://jsonnet.org\n",
      "Author: David Cunningham\n",
      "Author-email: dcunnin@google.com\n",
      "License: Apache License 2.0\n",
      "Location: /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages\n",
      "Requires: \n",
      "Required-by: allennlp\n",
      "g++ (Ubuntu 7.5.0-6ubuntu2) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "gcc (Ubuntu 7.5.0-6ubuntu2) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "Python 3.7.13\n",
      "Name: allennlp\n",
      "Version: 1.2.2\n",
      "Summary: An open-source NLP research library, built on PyTorch.\n",
      "Home-page: https://github.com/allenai/allennlp\n",
      "Author: Allen Institute for Artificial Intelligence\n",
      "Author-email: allennlp@allenai.org\n",
      "License: Apache\n",
      "Location: /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages\n",
      "Requires: boto3, filelock, h5py, jsonnet, jsonpickle, nltk, numpy, overrides, pytest, requests, scikit-learn, scipy, spacy, tensorboardX, torch, tqdm, transformers\n",
      "Required-by: allennlp-models\n",
      "Name: torch\n",
      "Version: 1.7.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages\n",
      "Requires: dataclasses, future, numpy, typing-extensions\n",
      "Required-by: allennlp, allennlp-models, torchvision\n",
      "Name: transformers\n",
      "Version: 3.4.0\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Sylvain Gugger, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: /home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages\n",
      "Requires: filelock, numpy, packaging, protobuf, regex, requests, sacremoses, sentencepiece, tokenizers, tqdm\n",
      "Required-by: allennlp\n",
      "conda 4.5.11\n",
      "GLIBCXX_3.4\n",
      "GLIBCXX_3.4.1\n",
      "GLIBCXX_3.4.2\n",
      "GLIBCXX_3.4.3\n",
      "GLIBCXX_3.4.4\n",
      "GLIBCXX_3.4.5\n",
      "GLIBCXX_3.4.6\n",
      "GLIBCXX_3.4.7\n",
      "GLIBCXX_3.4.8\n",
      "GLIBCXX_3.4.9\n",
      "GLIBCXX_3.4.10\n",
      "GLIBCXX_3.4.11\n",
      "GLIBCXX_3.4.12\n",
      "GLIBCXX_3.4.13\n",
      "GLIBCXX_3.4.14\n",
      "GLIBCXX_3.4.15\n",
      "GLIBCXX_3.4.16\n",
      "GLIBCXX_3.4.17\n",
      "GLIBCXX_3.4.18\n",
      "GLIBCXX_3.4.19\n",
      "GLIBCXX_3.4.20\n",
      "GLIBCXX_3.4.21\n",
      "GLIBCXX_3.4.22\n",
      "GLIBCXX_3.4.23\n",
      "GLIBCXX_3.4.24\n",
      "GLIBCXX_3.4.25\n",
      "GLIBCXX_3.4.26\n",
      "GLIBCXX_3.4.27\n",
      "GLIBCXX_3.4.28\n",
      "GLIBCXX_3.4.29\n",
      "GLIBCXX_3.4.30\n",
      "GLIBCXX_3.4.31\n",
      "GLIBCXX_3.4.32\n",
      "GLIBCXX_3.4.33\n",
      "GLIBCXX_TUNABLES\n",
      "GLIBCXX_DEBUG_MESSAGE_LENGTH\n",
      "lrwxrwxrwx 1 root root 19 Apr 12 12:30 /usr/lib/x86_64-linux-gnu/libstdc++.so.6 -> libstdc++.so.6.0.33\n"
     ]
    }
   ],
   "source": [
    "!lsb_release -a\n",
    "!cython --version\n",
    "!pip show jsonnet\n",
    "!g++ --version\n",
    "!gcc --version\n",
    "!python --version\n",
    "!pip show allennlp\n",
    "!pip show torch\n",
    "!pip show transformers\n",
    "!conda --version\n",
    "!strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX\n",
    "!ls -la /usr/lib/x86_64-linux-gnu/libstdc++.so.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.cuda.device"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'torch.device' has no attribute 'is_available'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32984/3829149415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'torch.device' has no attribute 'is_available'"
     ]
    }
   ],
   "source": [
    "torch.device.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!export PYTHONWARNINGS='ignore:semaphore_tracker:UserWarning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "srSNwqUz-39x",
    "outputId": "ea64d480-1136-4e88-c0c6-e44eb28805d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 82% | 61% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% | 96% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 80% | 61% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% | 96% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n",
      "{'weights_dir': PosixPath('outputs/muse/seed_42/weights')}\n",
      "{'random_seed': 42}\n",
      "{'pytorch_seed': 42}\n",
      "{'numpy_seed': 42}\n",
      "{'train_data_path': PosixPath('/home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/train.json')}\n",
      "{'validation_data_path': PosixPath('/home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/validation.json')}\n",
      "{'test_data_path': PosixPath('/home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/test.json')}\n",
      "{'path_config': PosixPath('outputs/muse/seed_42/config.jsonnet')}\n",
      "{'command': 'cd /home/ubuntu/Span-ASTE && allennlp train outputs/muse/seed_42/config.jsonnet --serialization-dir outputs/muse/seed_42/weights --include-package span_model'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "2024-07-18 17:05:43,510 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2024-07-18 17:05:43,867 - INFO - allennlp.common.params - include_in_archive = None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:05:43,868 - INFO - allennlp.common.params - random_seed = 42\n",
      "2024-07-18 17:05:43,868 - INFO - allennlp.common.params - numpy_seed = 42\n",
      "2024-07-18 17:05:43,868 - INFO - allennlp.common.params - pytorch_seed = 42\n",
      "2024-07-18 17:05:43,869 - INFO - allennlp.common.checks - Pytorch version: 1.7.0\n",
      "2024-07-18 17:05:43,870 - INFO - allennlp.common.params - type = default\n",
      "2024-07-18 17:05:43,870 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2024-07-18 17:05:43,871 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2024-07-18 17:05:43,871 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2024-07-18 17:05:43,871 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2024-07-18 17:05:43,871 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2024-07-18 17:05:43,871 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2024-07-18 17:05:43,871 - INFO - allennlp.common.params - dataset_reader.max_span_width = 4\n",
      "2024-07-18 17:05:43,871 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2024-07-18 17:05:43,872 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2024-07-18 17:05:43,872 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
      "2024-07-18 17:05:43,872 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2024-07-18 17:05:43,872 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2024-07-18 17:05:43,872 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "################################################################################\n",
      "2024-07-18 17:05:45,394 - INFO - allennlp.common.params - train_data_path = /home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/train.json\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7b896cb65050>\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.common.params - validation_data_path = /home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/validation.json\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.common.params - validation_data_loader = None\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.common.params - test_data_path = /home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/test.json\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.common.params - evaluate_on_test = False\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.common.params - batch_weight_key =\n",
      "2024-07-18 17:05:45,395 - INFO - allennlp.training.util - Reading training data from /home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading instances: 2381it [00:06, 349.84it/s]\n",
      "reading instances: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': '/home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/train.json', 'stats': Stats(entity_total=10299, entity_drop=627, relation_total=5468, relation_drop=593, graph_total=0, graph_edges=0, grid_total=28786590, grid_paired=14014)}\n",
      "2024-07-18 17:05:52,202 - INFO - allennlp.training.util - Reading validation data from /home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/validation.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading instances: 450it [00:01, 306.19it/s]\n",
      "reading instances: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': '/home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/validation.json', 'stats': Stats(entity_total=2006, entity_drop=137, relation_total=1054, relation_drop=125, graph_total=0, graph_edges=0, grid_total=6196354, grid_paired=2791)}\n",
      "2024-07-18 17:05:53,673 - INFO - allennlp.training.util - Reading test data from /home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading instances: 450it [00:01, 278.81it/s]\n",
      "building vocab: 479it [00:00, 4787.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': '/home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/test.json', 'stats': Stats(entity_total=2006, entity_drop=137, relation_total=1054, relation_drop=125, graph_total=0, graph_edges=0, grid_total=6196354, grid_paired=2791)}\n",
      "2024-07-18 17:05:55,287 - INFO - allennlp.common.params - type = from_instances\n",
      "2024-07-18 17:05:55,288 - INFO - allennlp.common.params - min_count = None\n",
      "2024-07-18 17:05:55,288 - INFO - allennlp.common.params - max_vocab_size = None\n",
      "2024-07-18 17:05:55,288 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
      "2024-07-18 17:05:55,288 - INFO - allennlp.common.params - pretrained_files = None\n",
      "2024-07-18 17:05:55,288 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
      "2024-07-18 17:05:55,288 - INFO - allennlp.common.params - tokens_to_add = None\n",
      "2024-07-18 17:05:55,288 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
      "2024-07-18 17:05:55,288 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
      "2024-07-18 17:05:55,289 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
      "2024-07-18 17:05:55,289 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "building vocab: 3281it [00:00, 5054.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:05:55,939 - INFO - allennlp.common.params - model.type = span_model\n",
      "2024-07-18 17:05:55,939 - INFO - allennlp.common.params - model.embedder.type = basic\n",
      "2024-07-18 17:05:55,940 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
      "2024-07-18 17:05:55,940 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
      "2024-07-18 17:05:55,940 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
      "2024-07-18 17:05:55,940 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
      "2024-07-18 17:05:55,940 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
      "2024-07-18 17:05:55,940 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
      "2024-07-18 17:05:55,940 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
      "2024-07-18 17:05:55,940 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
      "2024-07-18 17:05:59,750 - INFO - allennlp.common.params - model.modules.ner.focal_loss_gamma = 2\n",
      "2024-07-18 17:05:59,750 - INFO - allennlp.common.params - model.modules.ner.neg_class_weight = -1\n",
      "2024-07-18 17:05:59,750 - INFO - allennlp.common.params - model.modules.ner.use_bi_affine = False\n",
      "2024-07-18 17:05:59,750 - INFO - allennlp.common.params - model.modules.ner.use_double_scorer = False\n",
      "2024-07-18 17:05:59,750 - INFO - allennlp.common.params - model.modules.ner.use_focal_loss = False\n",
      "2024-07-18 17:05:59,750 - INFO - allennlp.common.params - model.modules.ner.use_gold_for_train_prune_scores = False\n",
      "2024-07-18 17:05:59,750 - INFO - allennlp.common.params - model.modules.ner.use_single_pool = False\n",
      "2024-07-18 17:05:59,750 - INFO - allennlp.common.params - model.modules.relation.focal_loss_gamma = 2\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.neg_class_weight = -1\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.span_length_loss_weight_gamma = 0\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_bag_pair_scorer = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_classifier = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_pruner = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_v2 = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_classify_mask_pruner = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_focal_loss = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_ner_scores_for_prune = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_ope_down_project = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_cls = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_maxpool = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_multiply = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_pairwise_down_project = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_single_pool = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_span_loss_for_pruners = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task = False\n",
      "2024-07-18 17:05:59,751 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task_after_prune = False\n",
      "2024-07-18 17:05:59,752 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2024-07-18 17:05:59,752 - INFO - allennlp.common.params - model.max_span_width = 4\n",
      "2024-07-18 17:05:59,752 - INFO - allennlp.common.params - model.target_task = relation\n",
      "2024-07-18 17:05:59,753 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal\n",
      "2024-07-18 17:05:59,753 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0\n",
      "2024-07-18 17:05:59,753 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None\n",
      "2024-07-18 17:05:59,753 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
      "2024-07-18 17:05:59,754 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
      "2024-07-18 17:05:59,754 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
      "2024-07-18 17:05:59,754 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
      "2024-07-18 17:05:59,754 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
      "2024-07-18 17:05:59,754 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2024-07-18 17:05:59,754 - INFO - allennlp.common.params - model.display_metrics = None\n",
      "2024-07-18 17:05:59,754 - INFO - allennlp.common.params - model.use_ner_embeds = False\n",
      "2024-07-18 17:05:59,754 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
      "2024-07-18 17:05:59,755 - INFO - allennlp.common.params - model.use_double_mix_embedder = False\n",
      "2024-07-18 17:05:59,755 - INFO - allennlp.common.params - model.relation_head_type = proper\n",
      "2024-07-18 17:05:59,755 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
      "2024-07-18 17:05:59,755 - INFO - allennlp.common.params - model.use_bilstm_after_embedder = False\n",
      "{'locals': ('use_ner_embeds', False)}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_double_mix_embedder', False)}\n",
      "{'locals': ('relation_head_type', 'proper')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.regularizer = None\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.use_bi_affine = False\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.neg_class_weight = -1\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.use_focal_loss = False\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.focal_loss_gamma = 2\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.use_double_scorer = False\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.use_gold_for_train_prune_scores = False\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.use_single_pool = False\n",
      "2024-07-18 17:05:59,756 - INFO - allennlp.common.params - ner.name = ner_labels\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "2024-07-18 17:05:59,760 - INFO - allennlp.common.params - relation.regularizer = None\n",
      "2024-07-18 17:05:59,760 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
      "2024-07-18 17:05:59,760 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
      "2024-07-18 17:05:59,760 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
      "2024-07-18 17:05:59,760 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.use_pair_feature_maxpool = False\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.use_pair_feature_cls = False\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.use_bi_affine_classifier = False\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.neg_class_weight = -1\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.span_length_loss_weight_gamma = 0\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.use_bag_pair_scorer = False\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.use_bi_affine_v2 = False\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.use_pruning = True\n",
      "2024-07-18 17:05:59,761 - INFO - allennlp.common.params - relation.use_single_pool = False\n",
      "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7b88939fb680>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__ner_labels, Size: 3 || None__tag_labels, Size: 9 || None__relation_labels, Size: 3 || Non Padded Namespaces: {'*tags', '*labels'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n",
      "2024-07-18 17:05:59,773 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2024-07-18 17:05:59,774 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2024-07-18 17:05:59,777 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2024-07-18 17:05:59,777 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
      "2024-07-18 17:05:59,777 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2024-07-18 17:05:59,778 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2024-07-18 17:05:59,778 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2024-07-18 17:05:59,778 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2024-07-18 17:05:59,778 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
      "2024-07-18 17:05:59,778 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2024-07-18 17:05:59,778 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
      "2024-07-18 17:05:59,778 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
      "2024-07-18 17:05:59,784 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
      "2024-07-18 17:05:59,784 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
      "2024-07-18 17:05:59,784 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2024-07-18 17:05:59,784 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2024-07-18 17:05:59,785 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2024-07-18 17:05:59,785 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2024-07-18 17:05:59,785 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
      "2024-07-18 17:05:59,785 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2024-07-18 17:05:59,785 - INFO - allennlp.nn.initializers - Initializing _endpoint_span_extractor._span_width_embedding.weight using _span_width_embedding.weight initializer\n",
      "2024-07-18 17:05:59,787 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2024-07-18 17:05:59,787 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2024-07-18 17:05:59,787 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2024-07-18 17:05:59,787 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2024-07-18 17:05:59,787 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,788 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2024-07-18 17:05:59,789 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,790 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2024-07-18 17:05:59,791 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2024-07-18 17:05:59,792 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2024-07-18 17:05:59,793 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2024-07-18 17:05:59,794 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,795 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2024-07-18 17:05:59,796 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
      "2024-07-18 17:05:59,797 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
      "2024-07-18 17:05:59,798 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2024-07-18 17:05:59,799 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2024-07-18 17:05:59,799 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2024-07-18 17:05:59,799 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2024-07-18 17:05:59,799 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2024-07-18 17:05:59,799 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2024-07-18 17:05:59,799 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2024-07-18 17:05:59,799 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2024-07-18 17:05:59,799 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2024-07-18 17:05:59,800 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2024-07-18 17:05:59,800 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2024-07-18 17:05:59,800 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2024-07-18 17:05:59,800 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2024-07-18 17:05:59,800 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2024-07-18 17:05:59,801 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2024-07-18 17:05:59,801 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2024-07-18 17:05:59,801 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2024-07-18 17:05:59,801 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2024-07-18 17:05:59,801 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2024-07-18 17:05:59,801 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2024-07-18 17:05:59,801 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2024-07-18 17:05:59,801 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2024-07-18 17:05:59,802 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2024-07-18 17:05:59,802 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2024-07-18 17:05:59,802 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2024-07-18 17:05:59,802 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2024-07-18 17:05:59,802 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2024-07-18 17:05:59,802 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2024-07-18 17:05:59,802 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.batch_size = 1\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
      "2024-07-18 17:05:59,803 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
      "2024-07-18 17:05:59,804 - INFO - allennlp.common.params - data_loader.sampler.type = random\n",
      "2024-07-18 17:05:59,804 - INFO - allennlp.common.params - data_loader.sampler.replacement = False\n",
      "2024-07-18 17:05:59,804 - INFO - allennlp.common.params - data_loader.sampler.num_samples = None\n",
      "2024-07-18 17:05:59,804 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.patience = None\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.validation_metric = +MEAN__relation_f1\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.num_epochs = 10\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.cuda_device = 7\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.grad_norm = 5\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.distributed = False\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.world_size = 1\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.use_amp = False\n",
      "2024-07-18 17:05:59,805 - INFO - allennlp.common.params - trainer.no_grad = None\n",
      "2024-07-18 17:05:59,806 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
      "2024-07-18 17:05:59,806 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7b896cbbf210>\n",
      "2024-07-18 17:05:59,806 - INFO - allennlp.common.params - trainer.moving_average = None\n",
      "2024-07-18 17:05:59,806 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
      "2024-07-18 17:05:59,806 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
      "2024-07-18 17:05:59,806 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
      "2024-07-18 17:05:59,806 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
      "2024-07-18 17:06:08,448 - INFO - allennlp.common.params - trainer.optimizer.type = adamw\n",
      "2024-07-18 17:06:08,448 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\n",
      "2024-07-18 17:06:08,449 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
      "2024-07-18 17:06:08,449 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
      "2024-07-18 17:06:08,449 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0\n",
      "2024-07-18 17:06:08,449 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
      "2024-07-18 17:06:08,450 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
      "2024-07-18 17:06:08,450 - INFO - allennlp.training.optimizers - Group 0: ['_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias', '_embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight'], {'finetune': True, 'lr': 5e-05, 'weight_decay': 0.01}\n",
      "2024-07-18 17:06:08,450 - INFO - allennlp.training.optimizers - Group 1: [], {'lr': 0.01}\n",
      "2024-07-18 17:06:08,450 - INFO - allennlp.training.optimizers - Group 2: ['_ner._ner_scorers.None__ner_labels.1._module.weight', '_relation._relation_scorers.None__relation_labels.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias', '_ner._ner_scorers.None__ner_labels.1._module.bias', '_relation._relation_scorers.None__relation_labels.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias', '_endpoint_span_extractor._span_width_embedding.weight', '_relation.d_embedder.embedder.weight', '_relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias', '_relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias', '_ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight'], {}\n",
      "2024-07-18 17:06:08,450 - WARNING - allennlp.training.optimizers - When constructing parameter groups, scalar_parameters does not match any parameter name\n",
      "2024-07-18 17:06:08,451 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110249657\n",
      "2024-07-18 17:06:08,453 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
      "2024-07-18 17:06:08,455 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
      "2024-07-18 17:06:08,455 - INFO - allennlp.common.util - _endpoint_span_extractor._span_width_embedding.weight\n",
      "2024-07-18 17:06:08,455 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2024-07-18 17:06:08,455 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2024-07-18 17:06:08,455 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,456 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,457 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,458 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,459 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,460 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,461 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2024-07-18 17:06:08,462 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2024-07-18 17:06:08,463 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2024-07-18 17:06:08,464 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2024-07-18 17:06:08,465 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2024-07-18 17:06:08,466 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2024-07-18 17:06:08,467 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2024-07-18 17:06:08,468 - INFO - allennlp.common.util - _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _relation.d_embedder.embedder.weight\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.weight\n",
      "2024-07-18 17:06:08,469 - INFO - allennlp.common.util - _relation._relation_scorers.None__relation_labels.bias\n",
      "2024-07-18 17:06:08,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
      "2024-07-18 17:06:08,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
      "2024-07-18 17:06:08,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.ratio = 32\n",
      "2024-07-18 17:06:08,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1\n",
      "2024-07-18 17:06:08,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = False\n",
      "2024-07-18 17:06:08,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = False\n",
      "2024-07-18 17:06:08,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.38\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - trainer.checkpointer.type = default\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - trainer.checkpointer.keep_serialized_model_every_num_seconds = None\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - trainer.checkpointer.num_serialized_models_to_keep = 1\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - trainer.checkpointer.model_save_interval = None\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - summary_interval = 100\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - histogram_interval = None\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - batch_size_interval = None\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
      "2024-07-18 17:06:08,471 - INFO - allennlp.common.params - get_batch_num_total = None\n",
      "2024-07-18 17:06:08,474 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "2024-07-18 17:06:08,488 - INFO - allennlp.training.trainer - Beginning training.\n",
      "2024-07-18 17:06:08,488 - INFO - allennlp.training.trainer - Epoch 0/9\n",
      "2024-07-18 17:06:08,488 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:06:08,488 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:06:08,489 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/2381 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:06:09,180 - WARNING - allennlp.training.util - Metrics with names beginning with \"_\" will not be logged to the tqdm progress bar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MEAN__relation_precision: 0.0012, MEAN__relation_recall: 0.0038, MEAN__relation_f1: 0.0018, batch_loss: 4.6985, loss: 55.1963 ||: 100%|##########| 2381/2381 [05:21<00:00,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:11:31,724 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 1.0000, MEAN__relation_recall: 0.0077, MEAN__relation_f1: 0.0152, batch_loss: 18.5898, loss: 21.1116 ||: 100%|##########| 450/450 [00:19<00:00, 22.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:11:51,703 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:11:51,705 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.002  |     0.015\n",
      "2024-07-18 17:11:51,705 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.001  |     1.000\n",
      "2024-07-18 17:11:51,706 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.004  |     0.008\n",
      "2024-07-18 17:11:51,706 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.179  |     0.269\n",
      "2024-07-18 17:11:51,706 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.279  |     0.679\n",
      "2024-07-18 17:11:51,706 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.131  |     0.167\n",
      "2024-07-18 17:11:51,707 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.179  |     0.269\n",
      "2024-07-18 17:11:51,707 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.279  |     0.679\n",
      "2024-07-18 17:11:51,707 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.131  |     0.167\n",
      "2024-07-18 17:11:51,707 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.002  |     0.015\n",
      "2024-07-18 17:11:51,708 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.001  |     1.000\n",
      "2024-07-18 17:11:51,710 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.004  |     0.008\n",
      "2024-07-18 17:11:51,711 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:11:51,712 - INFO - allennlp.training.tensorboard_writer - loss                      |    55.196  |    21.112\n",
      "2024-07-18 17:11:51,712 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4472.988  |       N/A\n",
      "2024-07-18 17:11:53,698 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/muse/seed_42/weights/best.th'.\n",
      "2024-07-18 17:11:54,135 - INFO - allennlp.training.trainer - Epoch duration: 0:05:45.646831\n",
      "2024-07-18 17:11:54,135 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:51:50\n",
      "2024-07-18 17:11:54,135 - INFO - allennlp.training.trainer - Epoch 1/9\n",
      "2024-07-18 17:11:54,136 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:11:54,136 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:11:54,137 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.4695, MEAN__relation_recall: 0.0454, MEAN__relation_f1: 0.0828, batch_loss: 10.2925, loss: 20.7294 ||: 100%|##########| 2381/2381 [05:05<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:17:00,822 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.5943, MEAN__relation_recall: 0.0483, MEAN__relation_f1: 0.0894, batch_loss: 14.3805, loss: 20.2065 ||: 100%|##########| 450/450 [00:17<00:00, 25.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:17:18,427 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:17:18,427 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.083  |     0.089\n",
      "2024-07-18 17:17:18,427 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.470  |     0.594\n",
      "2024-07-18 17:17:18,428 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.045  |     0.048\n",
      "2024-07-18 17:17:18,428 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.448  |     0.405\n",
      "2024-07-18 17:17:18,428 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.647  |     0.654\n",
      "2024-07-18 17:17:18,428 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.343  |     0.293\n",
      "2024-07-18 17:17:18,428 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.448  |     0.405\n",
      "2024-07-18 17:17:18,429 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.647  |     0.654\n",
      "2024-07-18 17:17:18,429 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.343  |     0.293\n",
      "2024-07-18 17:17:18,430 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.083  |     0.089\n",
      "2024-07-18 17:17:18,431 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.470  |     0.594\n",
      "2024-07-18 17:17:18,433 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.045  |     0.048\n",
      "2024-07-18 17:17:18,434 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:17:18,434 - INFO - allennlp.training.tensorboard_writer - loss                      |    20.729  |    20.207\n",
      "2024-07-18 17:17:18,434 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4533.906  |       N/A\n",
      "2024-07-18 17:17:20,425 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/muse/seed_42/weights/best.th'.\n",
      "2024-07-18 17:17:23,428 - INFO - allennlp.training.trainer - Epoch duration: 0:05:29.292652\n",
      "2024-07-18 17:17:23,428 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:44:59\n",
      "2024-07-18 17:17:23,428 - INFO - allennlp.training.trainer - Epoch 2/9\n",
      "2024-07-18 17:17:23,429 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:17:23,429 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:17:23,430 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.5393, MEAN__relation_recall: 0.1323, MEAN__relation_f1: 0.2125, batch_loss: 19.3682, loss: 16.1062 ||: 100%|##########| 2381/2381 [05:13<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:22:37,730 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.4755, MEAN__relation_recall: 0.0966, MEAN__relation_f1: 0.1606, batch_loss: 46.8613, loss: 29.6909 ||: 100%|##########| 450/450 [00:18<00:00, 24.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:22:56,331 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:22:56,331 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.212  |     0.161\n",
      "2024-07-18 17:22:56,332 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.539  |     0.475\n",
      "2024-07-18 17:22:56,332 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.132  |     0.097\n",
      "2024-07-18 17:22:56,332 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.643  |     0.502\n",
      "2024-07-18 17:22:56,332 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.760  |     0.570\n",
      "2024-07-18 17:22:56,333 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.557  |     0.448\n",
      "2024-07-18 17:22:56,333 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.643  |     0.502\n",
      "2024-07-18 17:22:56,333 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.760  |     0.570\n",
      "2024-07-18 17:22:56,334 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.557  |     0.448\n",
      "2024-07-18 17:22:56,334 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.212  |     0.161\n",
      "2024-07-18 17:22:56,337 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.539  |     0.475\n",
      "2024-07-18 17:22:56,338 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.132  |     0.097\n",
      "2024-07-18 17:22:56,338 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:22:56,338 - INFO - allennlp.training.tensorboard_writer - loss                      |    16.106  |    29.691\n",
      "2024-07-18 17:22:56,339 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4533.906  |       N/A\n",
      "2024-07-18 17:22:58,387 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/muse/seed_42/weights/best.th'.\n",
      "2024-07-18 17:23:01,368 - INFO - allennlp.training.trainer - Epoch duration: 0:05:37.939237\n",
      "2024-07-18 17:23:01,368 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:39:23\n",
      "2024-07-18 17:23:01,368 - INFO - allennlp.training.trainer - Epoch 3/9\n",
      "2024-07-18 17:23:01,368 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:23:01,368 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:23:01,369 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.6175, MEAN__relation_recall: 0.2312, MEAN__relation_f1: 0.3364, batch_loss: 4.9923, loss: 12.2649 ||: 100%|##########| 2381/2381 [05:04<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:28:07,004 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.6250, MEAN__relation_recall: 0.0690, MEAN__relation_f1: 0.1243, batch_loss: 82.1374, loss: 36.7981 ||: 100%|##########| 450/450 [00:17<00:00, 25.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:28:24,553 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:28:24,553 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.336  |     0.124\n",
      "2024-07-18 17:28:24,554 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.617  |     0.625\n",
      "2024-07-18 17:28:24,555 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.231  |     0.069\n",
      "2024-07-18 17:28:24,555 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.761  |     0.475\n",
      "2024-07-18 17:28:24,555 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.822  |     0.616\n",
      "2024-07-18 17:28:24,555 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.709  |     0.387\n",
      "2024-07-18 17:28:24,556 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.761  |     0.475\n",
      "2024-07-18 17:28:24,556 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.822  |     0.616\n",
      "2024-07-18 17:28:24,556 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.709  |     0.387\n",
      "2024-07-18 17:28:24,556 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.336  |     0.124\n",
      "2024-07-18 17:28:24,557 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.617  |     0.625\n",
      "2024-07-18 17:28:24,560 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.231  |     0.069\n",
      "2024-07-18 17:28:24,560 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:28:24,560 - INFO - allennlp.training.tensorboard_writer - loss                      |    12.265  |    36.798\n",
      "2024-07-18 17:28:24,560 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4540.129  |       N/A\n",
      "2024-07-18 17:28:26,759 - INFO - allennlp.training.trainer - Epoch duration: 0:05:25.391429\n",
      "2024-07-18 17:28:26,760 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:33:27\n",
      "2024-07-18 17:28:26,760 - INFO - allennlp.training.trainer - Epoch 4/9\n",
      "2024-07-18 17:28:26,760 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:28:26,760 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:28:26,761 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.6657, MEAN__relation_recall: 0.3060, MEAN__relation_f1: 0.4193, batch_loss: 0.3172, loss: 9.8379 ||: 100%|##########| 2381/2381 [05:03<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:33:31,503 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.4203, MEAN__relation_recall: 0.1334, MEAN__relation_f1: 0.2026, batch_loss: 5.5339, loss: 33.6623 ||: 100%|##########| 450/450 [00:17<00:00, 25.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:33:49,045 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:33:49,045 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.419  |     0.203\n",
      "2024-07-18 17:33:49,045 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.666  |     0.420\n",
      "2024-07-18 17:33:49,045 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.306  |     0.133\n",
      "2024-07-18 17:33:49,046 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.836  |     0.508\n",
      "2024-07-18 17:33:49,046 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.870  |     0.527\n",
      "2024-07-18 17:33:49,047 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.804  |     0.491\n",
      "2024-07-18 17:33:49,047 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.836  |     0.508\n",
      "2024-07-18 17:33:49,047 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.870  |     0.527\n",
      "2024-07-18 17:33:49,047 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.804  |     0.491\n",
      "2024-07-18 17:33:49,048 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.419  |     0.203\n",
      "2024-07-18 17:33:49,051 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.666  |     0.420\n",
      "2024-07-18 17:33:49,051 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.306  |     0.133\n",
      "2024-07-18 17:33:49,051 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:33:49,052 - INFO - allennlp.training.tensorboard_writer - loss                      |     9.838  |    33.662\n",
      "2024-07-18 17:33:49,052 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4540.129  |       N/A\n",
      "2024-07-18 17:33:51,039 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/muse/seed_42/weights/best.th'.\n",
      "2024-07-18 17:33:54,023 - INFO - allennlp.training.trainer - Epoch duration: 0:05:27.263208\n",
      "2024-07-18 17:33:54,023 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:27:45\n",
      "2024-07-18 17:33:54,023 - INFO - allennlp.training.trainer - Epoch 5/9\n",
      "2024-07-18 17:33:54,024 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:33:54,024 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:33:54,025 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.7154, MEAN__relation_recall: 0.3775, MEAN__relation_f1: 0.4942, batch_loss: 0.0000, loss: 7.7404 ||: 100%|##########| 2381/2381 [05:03<00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:38:58,577 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.4527, MEAN__relation_recall: 0.1357, MEAN__relation_f1: 0.2088, batch_loss: 22.8893, loss: 45.1667 ||: 100%|##########| 450/450 [00:17<00:00, 25.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:39:16,109 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:39:16,109 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.494  |     0.209\n",
      "2024-07-18 17:39:16,110 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.715  |     0.453\n",
      "2024-07-18 17:39:16,110 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.377  |     0.136\n",
      "2024-07-18 17:39:16,110 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.888  |     0.524\n",
      "2024-07-18 17:39:16,111 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.912  |     0.549\n",
      "2024-07-18 17:39:16,111 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.865  |     0.501\n",
      "2024-07-18 17:39:16,111 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.888  |     0.524\n",
      "2024-07-18 17:39:16,111 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.912  |     0.549\n",
      "2024-07-18 17:39:16,112 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.865  |     0.501\n",
      "2024-07-18 17:39:16,112 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.494  |     0.209\n",
      "2024-07-18 17:39:16,115 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.715  |     0.453\n",
      "2024-07-18 17:39:16,115 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.377  |     0.136\n",
      "2024-07-18 17:39:16,116 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:39:16,116 - INFO - allennlp.training.tensorboard_writer - loss                      |     7.740  |    45.167\n",
      "2024-07-18 17:39:16,117 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4540.129  |       N/A\n",
      "2024-07-18 17:39:18,125 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/muse/seed_42/weights/best.th'.\n",
      "2024-07-18 17:39:21,110 - INFO - allennlp.training.trainer - Epoch duration: 0:05:27.086059\n",
      "2024-07-18 17:39:21,110 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:22:08\n",
      "2024-07-18 17:39:21,110 - INFO - allennlp.training.trainer - Epoch 6/9\n",
      "2024-07-18 17:39:21,110 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:39:21,110 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:39:21,112 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.7635, MEAN__relation_recall: 0.4404, MEAN__relation_f1: 0.5586, batch_loss: 0.0000, loss: 6.3475 ||: 100%|##########| 2381/2381 [05:00<00:00,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:44:22,819 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.4256, MEAN__relation_recall: 0.1273, MEAN__relation_f1: 0.1960, batch_loss: 80.5767, loss: 44.4030 ||: 100%|##########| 450/450 [00:17<00:00, 25.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:44:40,179 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:44:40,180 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.559  |     0.196\n",
      "2024-07-18 17:44:40,180 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.763  |     0.426\n",
      "2024-07-18 17:44:40,180 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.440  |     0.127\n",
      "2024-07-18 17:44:40,181 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.924  |     0.511\n",
      "2024-07-18 17:44:40,181 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.941  |     0.549\n",
      "2024-07-18 17:44:40,181 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.908  |     0.478\n",
      "2024-07-18 17:44:40,182 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.924  |     0.511\n",
      "2024-07-18 17:44:40,183 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.941  |     0.549\n",
      "2024-07-18 17:44:40,184 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.908  |     0.478\n",
      "2024-07-18 17:44:40,184 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.559  |     0.196\n",
      "2024-07-18 17:44:40,185 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.763  |     0.426\n",
      "2024-07-18 17:44:40,186 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.440  |     0.127\n",
      "2024-07-18 17:44:40,187 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:44:40,187 - INFO - allennlp.training.tensorboard_writer - loss                      |     6.347  |    44.403\n",
      "2024-07-18 17:44:40,188 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4540.129  |       N/A\n",
      "2024-07-18 17:44:42,387 - INFO - allennlp.training.trainer - Epoch duration: 0:05:21.276930\n",
      "2024-07-18 17:44:42,387 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:16:31\n",
      "2024-07-18 17:44:42,387 - INFO - allennlp.training.trainer - Epoch 7/9\n",
      "2024-07-18 17:44:42,387 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:44:42,388 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:44:42,389 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.8092, MEAN__relation_recall: 0.4967, MEAN__relation_f1: 0.6155, batch_loss: 6.2098, loss: 4.6624 ||: 100%|##########| 2381/2381 [04:59<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:49:42,519 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.3811, MEAN__relation_recall: 0.1488, MEAN__relation_f1: 0.2140, batch_loss: 50.9205, loss: 61.7669 ||: 100%|##########| 450/450 [00:17<00:00, 25.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:50:00,060 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:50:00,061 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.616  |     0.214\n",
      "2024-07-18 17:50:00,061 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.809  |     0.381\n",
      "2024-07-18 17:50:00,061 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.497  |     0.149\n",
      "2024-07-18 17:50:00,062 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.951  |     0.521\n",
      "2024-07-18 17:50:00,062 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.960  |     0.566\n",
      "2024-07-18 17:50:00,062 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.941  |     0.483\n",
      "2024-07-18 17:50:00,062 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.951  |     0.521\n",
      "2024-07-18 17:50:00,064 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.960  |     0.566\n",
      "2024-07-18 17:50:00,064 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.941  |     0.483\n",
      "2024-07-18 17:50:00,066 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.616  |     0.214\n",
      "2024-07-18 17:50:00,066 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.809  |     0.381\n",
      "2024-07-18 17:50:00,067 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.497  |     0.149\n",
      "2024-07-18 17:50:00,067 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:50:00,068 - INFO - allennlp.training.tensorboard_writer - loss                      |     4.662  |    61.767\n",
      "2024-07-18 17:50:00,068 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4540.129  |       N/A\n",
      "2024-07-18 17:50:02,077 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/muse/seed_42/weights/best.th'.\n",
      "2024-07-18 17:50:05,079 - INFO - allennlp.training.trainer - Epoch duration: 0:05:22.692151\n",
      "2024-07-18 17:50:05,080 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:59\n",
      "2024-07-18 17:50:05,080 - INFO - allennlp.training.trainer - Epoch 8/9\n",
      "2024-07-18 17:50:05,080 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:50:05,080 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:50:05,081 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.8441, MEAN__relation_recall: 0.5441, MEAN__relation_f1: 0.6617, batch_loss: 1.2172, loss: 3.4930 ||: 100%|##########| 2381/2381 [05:04<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:55:10,869 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.3996, MEAN__relation_recall: 0.1403, MEAN__relation_f1: 0.2077, batch_loss: 40.4552, loss: 70.4758 ||: 100%|##########| 450/450 [00:18<00:00, 24.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 17:55:29,587 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 17:55:29,587 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.662  |     0.208\n",
      "2024-07-18 17:55:29,587 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.844  |     0.400\n",
      "2024-07-18 17:55:29,588 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.544  |     0.140\n",
      "2024-07-18 17:55:29,588 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.967  |     0.517\n",
      "2024-07-18 17:55:29,588 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.973  |     0.529\n",
      "2024-07-18 17:55:29,588 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.961  |     0.506\n",
      "2024-07-18 17:55:29,588 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.967  |     0.517\n",
      "2024-07-18 17:55:29,589 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.973  |     0.529\n",
      "2024-07-18 17:55:29,590 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.961  |     0.506\n",
      "2024-07-18 17:55:29,591 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.662  |     0.208\n",
      "2024-07-18 17:55:29,593 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.844  |     0.400\n",
      "2024-07-18 17:55:29,593 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.544  |     0.140\n",
      "2024-07-18 17:55:29,594 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 17:55:29,594 - INFO - allennlp.training.tensorboard_writer - loss                      |     3.493  |    70.476\n",
      "2024-07-18 17:55:29,595 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4540.129  |       N/A\n",
      "2024-07-18 17:55:31,849 - INFO - allennlp.training.trainer - Epoch duration: 0:05:26.769434\n",
      "2024-07-18 17:55:31,849 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:29\n",
      "2024-07-18 17:55:31,850 - INFO - allennlp.training.trainer - Epoch 9/9\n",
      "2024-07-18 17:55:31,850 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
      "2024-07-18 17:55:31,850 - INFO - allennlp.training.trainer - GPU 0 memory usage: 0B\n",
      "2024-07-18 17:55:31,851 - INFO - allennlp.training.trainer - Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.8677, MEAN__relation_recall: 0.5780, MEAN__relation_f1: 0.6938, batch_loss: 0.0000, loss: 2.6256 ||: 100%|##########| 2381/2381 [05:01<00:00,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 18:00:34,564 - INFO - allennlp.training.trainer - Validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "MEAN__relation_precision: 0.3957, MEAN__relation_recall: 0.1541, MEAN__relation_f1: 0.2219, batch_loss: 53.8510, loss: 82.4099 ||: 100%|##########| 450/450 [00:17<00:00, 25.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-18 18:00:52,082 - INFO - allennlp.training.tensorboard_writer -                               Training |  Validation\n",
      "2024-07-18 18:00:52,082 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_f1         |     0.694  |     0.222\n",
      "2024-07-18 18:00:52,082 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_precision  |     0.868  |     0.396\n",
      "2024-07-18 18:00:52,083 - INFO - allennlp.training.tensorboard_writer - MEAN__relation_recall     |     0.578  |     0.154\n",
      "2024-07-18 18:00:52,083 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_f1             |     0.980  |     0.523\n",
      "2024-07-18 18:00:52,083 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_precision      |     0.982  |     0.541\n",
      "2024-07-18 18:00:52,083 - INFO - allennlp.training.tensorboard_writer - _MEAN__ner_recall         |     0.978  |     0.507\n",
      "2024-07-18 18:00:52,084 - INFO - allennlp.training.tensorboard_writer - _None__ner_f1             |     0.980  |     0.523\n",
      "2024-07-18 18:00:52,084 - INFO - allennlp.training.tensorboard_writer - _None__ner_precision      |     0.982  |     0.541\n",
      "2024-07-18 18:00:52,084 - INFO - allennlp.training.tensorboard_writer - _None__ner_recall         |     0.978  |     0.507\n",
      "2024-07-18 18:00:52,085 - INFO - allennlp.training.tensorboard_writer - _None__relation_f1        |     0.694  |     0.222\n",
      "2024-07-18 18:00:52,088 - INFO - allennlp.training.tensorboard_writer - _None__relation_precision |     0.868  |     0.396\n",
      "2024-07-18 18:00:52,088 - INFO - allennlp.training.tensorboard_writer - _None__relation_recall    |     0.578  |     0.154\n",
      "2024-07-18 18:00:52,088 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB           |     0.000  |       N/A\n",
      "2024-07-18 18:00:52,089 - INFO - allennlp.training.tensorboard_writer - loss                      |     2.626  |    82.410\n",
      "2024-07-18 18:00:52,089 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB        |  4540.129  |       N/A\n",
      "2024-07-18 18:00:54,053 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'outputs/muse/seed_42/weights/best.th'.\n",
      "2024-07-18 18:00:57,053 - INFO - allennlp.training.trainer - Epoch duration: 0:05:25.203293\n",
      "2024-07-18 18:00:57,053 - INFO - allennlp.training.checkpointer - loading best weights\n",
      "2024-07-18 18:00:57,432 - INFO - allennlp.commands.train - To evaluate on the test set after training, pass the 'evaluate_on_test' flag, or use the 'allennlp evaluate' command.\n",
      "2024-07-18 18:00:57,432 - INFO - allennlp.common.util - Metrics: {\n",
      "\"best_epoch\": 9,\n",
      "\"peak_worker_0_memory_MB\": 4540.12890625,\n",
      "\"peak_gpu_0_memory_MB\": 0,\n",
      "\"training_duration\": \"0:54:43.601030\",\n",
      "\"training_start_epoch\": 0,\n",
      "\"training_epochs\": 9,\n",
      "\"epoch\": 9,\n",
      "\"training__None__ner_precision\": 0.98214100301111,\n",
      "\"training__None__ner_recall\": 0.9779776674937966,\n",
      "\"training__None__ner_f1\": 0.9800549137439777,\n",
      "\"training__MEAN__ner_precision\": 0.98214100301111,\n",
      "\"training__MEAN__ner_recall\": 0.9779776674937966,\n",
      "\"training__MEAN__ner_f1\": 0.9800549137439777,\n",
      "\"training__None__relation_precision\": 0.8677283786772838,\n",
      "\"training__None__relation_recall\": 0.5780167968174451,\n",
      "\"training__None__relation_f1\": 0.6938450654403961,\n",
      "\"training_MEAN__relation_precision\": 0.8677283786772838,\n",
      "\"training_MEAN__relation_recall\": 0.5780167968174451,\n",
      "\"training_MEAN__relation_f1\": 0.6938450654403961,\n",
      "\"training_loss\": 2.625595081439881,\n",
      "\"training_worker_0_memory_MB\": 4540.12890625,\n",
      "\"training_gpu_0_memory_MB\": 0.0,\n",
      "\"validation__None__ner_precision\": 0.5405251141552512,\n",
      "\"validation__None__ner_recall\": 0.5066880684858213,\n",
      "\"validation__None__ner_f1\": 0.5230599281966307,\n",
      "\"validation__MEAN__ner_precision\": 0.5405251141552512,\n",
      "\"validation__MEAN__ner_recall\": 0.5066880684858213,\n",
      "\"validation__MEAN__ner_f1\": 0.5230599281966307,\n",
      "\"validation__None__relation_precision\": 0.3956692913385827,\n",
      "\"validation__None__relation_recall\": 0.15414110429447853,\n",
      "\"validation__None__relation_f1\": 0.2218543046357616,\n",
      "\"validation_MEAN__relation_precision\": 0.3956692913385827,\n",
      "\"validation_MEAN__relation_recall\": 0.15414110429447853,\n",
      "\"validation_MEAN__relation_f1\": 0.2218543046357616,\n",
      "\"validation_loss\": 82.40992927584293,\n",
      "\"best_validation__None__ner_precision\": 0.5405251141552512,\n",
      "\"best_validation__None__ner_recall\": 0.5066880684858213,\n",
      "\"best_validation__None__ner_f1\": 0.5230599281966307,\n",
      "\"best_validation__MEAN__ner_precision\": 0.5405251141552512,\n",
      "\"best_validation__MEAN__ner_recall\": 0.5066880684858213,\n",
      "\"best_validation__MEAN__ner_f1\": 0.5230599281966307,\n",
      "\"best_validation__None__relation_precision\": 0.3956692913385827,\n",
      "\"best_validation__None__relation_recall\": 0.15414110429447853,\n",
      "\"best_validation__None__relation_f1\": 0.2218543046357616,\n",
      "\"best_validation_MEAN__relation_precision\": 0.3956692913385827,\n",
      "\"best_validation_MEAN__relation_recall\": 0.15414110429447853,\n",
      "\"best_validation_MEAN__relation_f1\": 0.2218543046357616,\n",
      "\"best_validation_loss\": 82.40992927584293\n",
      "}\n",
      "2024-07-18 18:00:57,474 - INFO - allennlp.models.archival - archiving weights and vocabulary to outputs/muse/seed_42/weights/model.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!export PYTHONWARNINGS='ignore:semaphore_tracker:UserWarning'\n",
    "# Train SpanModel from scratch\n",
    "from wrapper import SpanModel\n",
    "import os\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore:semaphore_tracker:UserWarning'\n",
    "free_gpu_cache()\n",
    "data_name=\"muse\"\n",
    "random_seed =42\n",
    "path_train = f\"aste/data/triplet_data/{data_name}/train.txt\"\n",
    "path_dev = f\"aste/data/triplet_data/{data_name}/dev.txt\"\n",
    "path_test = f\"aste/data/triplet_data/{data_name}/test.txt\"\n",
    "save_dir = f\"outputs/{data_name}/seed_{random_seed}\"\n",
    "\n",
    "model = SpanModel(save_dir=save_dir, random_seed=random_seed)\n",
    "model.fit(path_train, path_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "yjyiKWjSF7oZ",
    "outputId": "4de93155-e180-4d05-aca2-2cf6e6eaa90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'command': 'cd /home/ubuntu/Span-ASTE && allennlp predict outputs/muse/seed_42/weights/model.tar.gz /home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/pred_in.json --predictor span_model --include-package span_model --use-dataset-reader  --output-file outputs/muse/seed_42/temp_data/pred_out.json --cuda-device 0 --silent '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "2024-07-18 18:36:48,904 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2024-07-18 18:36:49,220 - INFO - allennlp.models.archival - loading archive file outputs/muse/seed_42/weights/model.tar.gz\n",
      "2024-07-18 18:36:49,221 - INFO - allennlp.models.archival - extracting archive file outputs/muse/seed_42/weights/model.tar.gz to temp dir /tmp/tmpu1b2mxs0\n",
      "2024-07-18 18:36:53,563 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2024-07-18 18:36:53,565 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2024-07-18 18:36:53,565 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2024-07-18 18:36:53,565 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2024-07-18 18:36:53,565 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2024-07-18 18:36:53,565 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2024-07-18 18:36:53,565 - INFO - allennlp.common.params - dataset_reader.max_span_width = 4\n",
      "2024-07-18 18:36:53,566 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2024-07-18 18:36:53,566 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2024-07-18 18:36:53,566 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
      "2024-07-18 18:36:53,566 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2024-07-18 18:36:53,566 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2024-07-18 18:36:53,566 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "2024-07-18 18:36:55,052 - INFO - allennlp.common.params - dataset_reader.type = span_model\n",
      "2024-07-18 18:36:55,052 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
      "2024-07-18 18:36:55,052 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
      "2024-07-18 18:36:55,052 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2024-07-18 18:36:55,052 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2024-07-18 18:36:55,052 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
      "2024-07-18 18:36:55,052 - INFO - allennlp.common.params - dataset_reader.max_span_width = 4\n",
      "2024-07-18 18:36:55,053 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = pretrained_transformer_mismatched\n",
      "2024-07-18 18:36:55,053 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.token_min_padding_length = 0\n",
      "2024-07-18 18:36:55,053 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.model_name = bert-base-uncased\n",
      "2024-07-18 18:36:55,053 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.namespace = tags\n",
      "2024-07-18 18:36:55,053 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_length = 512\n",
      "2024-07-18 18:36:55,053 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.tokenizer_kwargs = None\n",
      "2024-07-18 18:36:55,054 - INFO - allennlp.common.params - type = from_instances\n",
      "2024-07-18 18:36:55,054 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpu1b2mxs0/vocabulary.\n",
      "2024-07-18 18:36:55,056 - INFO - allennlp.common.params - model.type = span_model\n",
      "2024-07-18 18:36:55,056 - INFO - allennlp.common.params - model.embedder.type = basic\n",
      "2024-07-18 18:36:55,056 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.type = pretrained_transformer_mismatched\n",
      "2024-07-18 18:36:55,057 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.model_name = bert-base-uncased\n",
      "2024-07-18 18:36:55,057 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.max_length = 512\n",
      "2024-07-18 18:36:55,057 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.train_parameters = True\n",
      "2024-07-18 18:36:55,057 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.last_layer_only = True\n",
      "2024-07-18 18:36:55,057 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.gradient_checkpointing = None\n",
      "2024-07-18 18:36:55,057 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.tokenizer_kwargs = None\n",
      "2024-07-18 18:36:55,057 - INFO - allennlp.common.params - model.embedder.token_embedders.bert.transformer_kwargs = None\n",
      "2024-07-18 18:36:58,815 - INFO - allennlp.common.params - model.modules.ner.focal_loss_gamma = 2\n",
      "2024-07-18 18:36:58,815 - INFO - allennlp.common.params - model.modules.ner.neg_class_weight = -1\n",
      "2024-07-18 18:36:58,815 - INFO - allennlp.common.params - model.modules.ner.use_bi_affine = False\n",
      "2024-07-18 18:36:58,815 - INFO - allennlp.common.params - model.modules.ner.use_double_scorer = False\n",
      "2024-07-18 18:36:58,815 - INFO - allennlp.common.params - model.modules.ner.use_focal_loss = False\n",
      "2024-07-18 18:36:58,815 - INFO - allennlp.common.params - model.modules.ner.use_gold_for_train_prune_scores = False\n",
      "2024-07-18 18:36:58,815 - INFO - allennlp.common.params - model.modules.ner.use_single_pool = False\n",
      "2024-07-18 18:36:58,815 - INFO - allennlp.common.params - model.modules.relation.focal_loss_gamma = 2\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.neg_class_weight = -1\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.span_length_loss_weight_gamma = 0\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.spans_per_word = 0.5\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_bag_pair_scorer = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_classifier = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_pruner = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_bi_affine_v2 = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_classify_mask_pruner = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_distance_embeds = True\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_focal_loss = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_ner_scores_for_prune = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_ope_down_project = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_cls = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_maxpool = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_pair_feature_multiply = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_pairwise_down_project = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_pruning = True\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_single_pool = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_span_loss_for_pruners = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.modules.relation.use_span_pair_aux_task_after_prune = False\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.feature_size = 20\n",
      "2024-07-18 18:36:58,816 - INFO - allennlp.common.params - model.max_span_width = 4\n",
      "2024-07-18 18:36:58,817 - INFO - allennlp.common.params - model.target_task = relation\n",
      "2024-07-18 18:36:58,817 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7a95e2e94450>\n",
      "2024-07-18 18:36:58,818 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.type = xavier_normal\n",
      "2024-07-18 18:36:58,818 - INFO - allennlp.common.params - model.module_initializer.regexes.0.1.gain = 1.0\n",
      "2024-07-18 18:36:58,818 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.type = xavier_normal\n",
      "2024-07-18 18:36:58,818 - INFO - allennlp.common.params - model.module_initializer.regexes.1.1.gain = 1.0\n",
      "2024-07-18 18:36:58,818 - INFO - allennlp.common.params - model.module_initializer.prevent_regexes = None\n",
      "2024-07-18 18:36:58,819 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2024-07-18 18:36:58,819 - INFO - allennlp.common.params - model.display_metrics = None\n",
      "2024-07-18 18:36:58,819 - INFO - allennlp.common.params - model.use_ner_embeds = False\n",
      "2024-07-18 18:36:58,819 - INFO - allennlp.common.params - model.span_extractor_type = endpoint\n",
      "2024-07-18 18:36:58,819 - INFO - allennlp.common.params - model.use_double_mix_embedder = False\n",
      "2024-07-18 18:36:58,819 - INFO - allennlp.common.params - model.relation_head_type = proper\n",
      "2024-07-18 18:36:58,819 - INFO - allennlp.common.params - model.use_span_width_embeds = True\n",
      "2024-07-18 18:36:58,819 - INFO - allennlp.common.params - model.use_bilstm_after_embedder = False\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.regularizer = None\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.use_bi_affine = False\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.neg_class_weight = -1\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.use_focal_loss = False\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.focal_loss_gamma = 2\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.use_double_scorer = False\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.use_gold_for_train_prune_scores = False\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.use_single_pool = False\n",
      "2024-07-18 18:36:58,820 - INFO - allennlp.common.params - ner.name = ner_labels\n",
      "2024-07-18 18:36:58,824 - INFO - allennlp.common.params - relation.regularizer = None\n",
      "2024-07-18 18:36:58,824 - INFO - allennlp.common.params - relation.serialization_dir = None\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.spans_per_word = 0.5\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.positive_label_weight = 1.0\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.use_distance_embeds = True\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.use_pair_feature_maxpool = False\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.use_pair_feature_cls = False\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.use_bi_affine_classifier = False\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.neg_class_weight = -1\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.span_length_loss_weight_gamma = 0\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.use_bag_pair_scorer = False\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.use_bi_affine_v2 = False\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.use_pruning = True\n",
      "2024-07-18 18:36:58,825 - INFO - allennlp.common.params - relation.use_single_pool = False\n",
      "2024-07-18 18:36:58,836 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2024-07-18 18:36:58,836 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.0.weight using .*weight initializer\n",
      "2024-07-18 18:36:58,839 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.0._module._linear_layers.1.weight using .*weight initializer\n",
      "2024-07-18 18:36:58,840 - INFO - allennlp.nn.initializers - Initializing _ner_scorers.None__ner_labels.1._module.weight using .*weight initializer\n",
      "2024-07-18 18:36:58,840 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2024-07-18 18:36:58,840 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2024-07-18 18:36:58,840 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2024-07-18 18:36:58,840 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2024-07-18 18:36:58,840 - INFO - allennlp.nn.initializers -    _ner_scorers.None__ner_labels.1._module.bias\n",
      "2024-07-18 18:36:58,840 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2024-07-18 18:36:58,840 - INFO - allennlp.nn.initializers - Initializing d_embedder.embedder.weight using .*weight initializer\n",
      "2024-07-18 18:36:58,840 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.0.weight using .*weight initializer\n",
      "2024-07-18 18:36:58,846 - INFO - allennlp.nn.initializers - Initializing _relation_feedforwards.None__relation_labels._linear_layers.1.weight using .*weight initializer\n",
      "2024-07-18 18:36:58,846 - INFO - allennlp.nn.initializers - Initializing _relation_scorers.None__relation_labels.weight using .*weight initializer\n",
      "2024-07-18 18:36:58,847 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*weight_matrix\n",
      "2024-07-18 18:36:58,847 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2024-07-18 18:36:58,847 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2024-07-18 18:36:58,847 - INFO - allennlp.nn.initializers -    _relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2024-07-18 18:36:58,847 - INFO - allennlp.nn.initializers -    _relation_scorers.None__relation_labels.bias\n",
      "2024-07-18 18:36:58,847 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.LayerNorm.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.position_embeddings.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.embeddings.word_embeddings.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2024-07-18 18:36:58,849 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,850 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,851 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,852 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2024-07-18 18:36:58,853 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2024-07-18 18:36:58,854 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _embedder.token_embedder_bert._matched_embedder.transformer_model.pooler.dense.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _endpoint_span_extractor._span_width_embedding.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.0.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.bias\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.0._module._linear_layers.1.weight\n",
      "2024-07-18 18:36:58,855 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.bias\n",
      "2024-07-18 18:36:58,856 - INFO - allennlp.nn.initializers -    _ner._ner_scorers.None__ner_labels.1._module.weight\n",
      "2024-07-18 18:36:58,856 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.bias\n",
      "2024-07-18 18:36:58,856 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.0.weight\n",
      "2024-07-18 18:36:58,856 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.bias\n",
      "2024-07-18 18:36:58,856 - INFO - allennlp.nn.initializers -    _relation._relation_feedforwards.None__relation_labels._linear_layers.1.weight\n",
      "2024-07-18 18:36:58,856 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.bias\n",
      "2024-07-18 18:36:58,856 - INFO - allennlp.nn.initializers -    _relation._relation_scorers.None__relation_labels.weight\n",
      "2024-07-18 18:36:58,856 - INFO - allennlp.nn.initializers -    _relation.d_embedder.embedder.weight\n",
      "2024-07-18 18:37:15,126 - INFO - root - Loading a model trained before embedding extension was implemented; pass an explicit vocab namespace if you want to extend the vocabulary.\n",
      "2024-07-18 18:37:16,141 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpu1b2mxs0\n",
      "reading instances: 450it [00:01, 320.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "################################################################################\n",
      "{'locals': ('use_ner_embeds', False)}\n",
      "{'locals': ('span_extractor_type', 'endpoint')}\n",
      "{'locals': ('use_double_mix_embedder', False)}\n",
      "{'locals': ('relation_head_type', 'proper')}\n",
      "{'locals': ('use_span_width_embeds', True)}\n",
      "{'ner_loss_fn': CrossEntropyLoss()}\n",
      "{'unused_keys': dict_keys(['focal_loss_gamma', 'use_bi_affine_pruner', 'use_classify_mask_pruner', 'use_focal_loss', 'use_ner_scores_for_prune', 'use_ope_down_project', 'use_pair_feature_multiply', 'use_pairwise_down_project', 'use_span_loss_for_pruners', 'use_span_pair_aux_task', 'use_span_pair_aux_task_after_prune'])}\n",
      "{'locals': {'self': ProperRelationExtractor(), 'make_feedforward': <function SpanModel.__init__.<locals>.make_feedforward at 0x7a95ddf707a0>, 'span_emb_dim': 1556, 'feature_size': 20, 'spans_per_word': 0.5, 'positive_label_weight': 1.0, 'regularizer': None, 'use_distance_embeds': True, 'use_pair_feature_maxpool': False, 'use_pair_feature_cls': False, 'use_bi_affine_classifier': False, 'neg_class_weight': -1, 'span_length_loss_weight_gamma': 0, 'use_bag_pair_scorer': False, 'use_bi_affine_v2': False, 'use_pruning': True, 'use_single_pool': False, 'kwargs': {'focal_loss_gamma': 2, 'use_bi_affine_pruner': False, 'use_classify_mask_pruner': False, 'use_focal_loss': False, 'use_ner_scores_for_prune': False, 'use_ope_down_project': False, 'use_pair_feature_multiply': False, 'use_pairwise_down_project': False, 'use_span_loss_for_pruners': False, 'use_span_pair_aux_task': False, 'use_span_pair_aux_task_after_prune': False}, 'vocab': Vocabulary with namespaces:  None__tag_labels, Size: 9 || None__relation_labels, Size: 3 || None__ner_labels, Size: 3 || Non Padded Namespaces: {'*labels', '*tags'}, '__class__': <class 'span_model.models.relation_proper.ProperRelationExtractor'>}}\n",
      "{'token_emb_dim': 768, 'span_emb_dim': 1556, 'relation_scorer_dim': 3240}\n",
      "{'relation_loss_fn': CrossEntropyLoss()}\n",
      "{'file_path': '/home/ubuntu/Span-ASTE/outputs/muse/seed_42/temp_data/pred_in.json', 'stats': Stats(entity_total=450, entity_drop=0, relation_total=450, relation_drop=0, graph_total=0, graph_edges=0, grid_total=6558521, grid_paired=450)}\n",
      "{\n",
      "  \"path_pred\": \"pred.txt\",\n",
      "  \"path_gold\": \"aste/data/triplet_data/muse/test.txt\",\n",
      "  \"precision\": 0.40932642487046633,\n",
      "  \"recall\": 0.171242774566474,\n",
      "  \"score\": 0.2414671421293938\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SpanModel F1 Score\n",
    "import json\n",
    "\n",
    "path_pred = \"pred.txt\"\n",
    "model.predict(path_in=path_test, path_out=path_pred)\n",
    "results = model.score(path_pred, path_test)\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488,
     "referenced_widgets": [
      "06ce7feacbfc47e696b005bda7d6fc52",
      "7e7961cebbbd4af988eadca9ebbc72a8",
      "57bf9771c66f48fb89f29c2138d64101",
      "df4cef36d642490eb23f0db462d8acf5",
      "ae3a872a5e084ae79d393a45bb4e75bb",
      "f989b846ca904d818d1c48c7fc43a301",
      "058ba503b3e3485298c0e84b3eb831f7",
      "bbd916234f834a61b154c6d1cbc16093",
      "4ff50cf0303e4f32b111582a8f1a7204",
      "be21ffc26a88423fa04274598782ca94",
      "13ae0428359f4af79ba13401d4b6a671",
      "b249aa7368d048a1aa0bb26fef197a3a",
      "978289baa03e4a728c91767e682c1e58",
      "53f0e9654c42432c936a7be756c2f1ad",
      "373b2bbdd6094405b5a3781e3ce8b854",
      "e17fae11370d48469a43723103510276",
      "d2137a1d41bf4654b2321b0e8b3179ea",
      "9819a63af0f349f3b7eda83464325600",
      "4ed85ff4e68d4c258dc7fc7a5eb60a0f",
      "9df7921ab61b4a8698e5dff835fd1ada",
      "68dcb517716848faaa1196b40d011954",
      "9739ad3b7a894a76956a305a5505c84f",
      "a1759abf000f433dbbcd8e3ace643b0c",
      "5e3e35bc02f9405fb467ba7cd1aee340",
      "3ee51e2dcd654f2caff137cff38f8bc9",
      "13cc94dcb00a470a87aaf3409b20a605",
      "c5f32837a20b480eb4f75f7ba357e443",
      "9ebd2d576b044d7aac22e3ef1cd7bf49",
      "8f1e31c6b0094f6a80da012841845920",
      "cad43e17e0194a9da9586158788e6757",
      "32b38abe23a74a569a3fe0895a36d54e",
      "2cf108605bd54f87a2ca6a5f505926df",
      "b64601c0d3d3465d8334080f24c50138",
      "46d6b1110d3d428d940f7b169250313f",
      "6f6f97e61db74ac8b351a2836191f15d",
      "119ea25862a6424dbd0281cc394dc215",
      "627a0977de4349019428352c7e9b9243",
      "3f6347036fe0464a8aead0d7fec311b2",
      "343bbfb6096d4dde9b415b7eae198e68",
      "c2b9230207404a03b87b1da87978873e",
      "afef86df3231491d9ff5ec09b5b7856b",
      "ccb2ccd455ae477d837e36f23bc185ec",
      "3192fada7cdc48719da3f03d31dc52f1",
      "68805c09bfc44d86a2f5d99cacc7551f"
     ]
    },
    "collapsed": false,
    "id": "r3i4rnIhapWe",
    "outputId": "c8d0d04b-ddd7-4f63-846f-f159bf080b35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'command': 'cd /home/ubuntu/Span-ASTE && allennlp predict muse/weights/model.tar.gz /home/ubuntu/Span-ASTE/muse/temp_data/pred_in.json --predictor span_model --include-package span_model --use-dataset-reader  --output-file muse/temp_data/pred_out.json --cuda-device 0 --silent '}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "2024-07-05 03:55:23,462 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/span/bin/allennlp\", line 8, in <module>\n",
      "    sys.exit(run())\n",
      "  File \"/home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages/allennlp/__main__.py\", line 34, in run\n",
      "    main(prog=\"allennlp\")\n",
      "  File \"/home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages/allennlp/commands/__init__.py\", line 118, in main\n",
      "    args.func(args)\n",
      "  File \"/home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 205, in _predict\n",
      "    predictor = _get_predictor(args)\n",
      "  File \"/home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages/allennlp/commands/predict.py\", line 110, in _get_predictor\n",
      "    overrides=args.overrides,\n",
      "  File \"/home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages/allennlp/models/archival.py\", line 181, in load_archive\n",
      "    resolved_archive_file = cached_path(archive_file)\n",
      "  File \"/home/ubuntu/anaconda3/envs/span/lib/python3.7/site-packages/allennlp/common/file_utils.py\", line 202, in cached_path\n",
      "    raise FileNotFoundError(f\"file {url_or_filename} not found\")\n",
      "FileNotFoundError: file muse/weights/model.tar.gz not found\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'muse/temp_data/pred_out.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_455963/1359813924.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Did not enjoy the new Windows 8 and touchscreen functions .\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpanModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_455963/1359813924.py\u001b[0m in \u001b[0;36mpredict_sentence\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSplitEnum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_full_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Span-ASTE/aste/wrapper.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, path_in, path_out)\u001b[0m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_temp_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSpanModelPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         data = Data(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'muse/temp_data/pred_out.json'"
     ]
    }
   ],
   "source": [
    "# Use pretrained SpanModel weights for prediction\n",
    "import sys\n",
    "sys.path.append(\"aste\")\n",
    "from pathlib import Path\n",
    "from data_utils import Data, Sentence, SplitEnum\n",
    "from wrapper import SpanModel\n",
    "\n",
    "def predict_sentence(text: str, model: SpanModel) -> Sentence:\n",
    "    path_in = \"temp_in.txt\"\n",
    "    path_out = \"temp_out.txt\"\n",
    "    sent = Sentence(tokens=text.split(), triples=[], pos=[], is_labeled=\n",
    "False, weight=1, id=0)\n",
    "    data = Data(root=Path(), data_split=SplitEnum.test, sentences=[sent])\n",
    "    data.save_to_path(path_in)\n",
    "    model.predict(path_in, path_out)\n",
    "    data = Data.load_from_full_path(path_out)\n",
    "    return data.sentences[0]\n",
    "\n",
    "text = \"Did not enjoy the new Windows 8 and touchscreen functions .\"\n",
    "model = SpanModel(save_dir=model_dir, random_seed=0)\n",
    "sent = predict_sentence(text, model)\n",
    "\n",
    "for t in sent.triples:\n",
    "    target = \" \".join(sent.tokens[t.t_start:t.t_end+1])\n",
    "    opinion = \" \".join(sent.tokens[t.o_start:t.o_end+1])\n",
    "    print()\n",
    "    print(dict(target=target, opinion=opinion, sentiment=t.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (span)",
   "language": "python",
   "name": "span"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
